This is a data warehouse for Tom's personal life

We start with these data marts.

Terminal commands
    From shell history files
Calendar events
    http://thomaslevine.com/schedule
Facebook messages
    Facebook messages that people have sent me (not messages I have sent)
Facebook chat status changes
    When people go online and offline
Twitter notifications
    When people direct message, follow, &c. me., based on emails from Twitter
GnuCash splits
    Along with their transactions, accounts, &c.
All my emails
    With ordinary email fields
Web logs from Branchable
    HTTP requests for http://thomaslevine.com
Piwik database
    Stuff that Piwik tracks for http://thomaslevine.com
Mutt aliases
    Person and email address

I link the following dimensions quite nicely because there is a clear
one-to-many relationship.

Person
    Real persons are linked to email addresses, Facebook accounts, &c.
Dates
    Dates and datetimes are converted into one thing.

Many-to-many relationships also work; I
`use <http://docs.sqlalchemy.org/en/latest/dialects/postgresql.html#sqlalchemy.dialects.postgresql.array>`_
PostgreSQL's `array type <http://www.postgresql.org/docs/9.1/static/arrays.html>`_.

Fuzzy person
    Real persons are guessed based on IP addresses, names, &c.
Topics
    Whether the fact references a particular topic, probably determined based on the presence of specific URLs and other key words.
Location
    I associate the fact with locations based on time zones, persons, topics, &c.

How to use
=======================================
Install the package. ::

    pip3 install .

Start loading the data. ::

    dada-load

More ideas of sources of data
========================================
Here are some other possible cubes or data sources.

* Git commits
* Project pages (``pip install tlevine``)
* Emails, possibly broken out as
  * Notifications from various services
  * Sent emails
  * Mailing lists
  * Travel bookings
  * ...
* Old calendar (Google Calendar)
* Other Google services, mainly for stuff from years ago
* Text messages
* Meetup.com history

Some tables to create to assist in the creation of these tools

* Unique identifiers for people with links to email addresses, phone
    numbers, &c.
* Cities I've been in, people I stayed with

Structure of the repository
==============================

``doeund``
    A separate package for assembling a model from sqlalchemy
``warehouse/{main,model,logger}.py``
    Overall configuration of the data warehouse
The rest of ``warehouse``
    Connectors to different data sources
``mastering``
    Assemblage of master data

Fun ideas
==============================

* How many spaces after a period?
* Connect website views to emails
* Length of sentences (Saar Golde's idea)
* http://www.pcthompson.co.uk/documents/The_Reverse_Star_Schema_v2.1.pdf

Maybe I am gonna write an OLAP server
==========================================
Here are some thoughts on that.

I'll define relationships on dimensions such that dimensions point to
their fact tables. When you slice on dimensions, the server queries the
dimension table, accesses the relationship, and continues the queries
all the way down. For example, consider the schema below.

* There is an email message fact table that contains a ``from_address``
    column.
* There is an email address dimension table that contains a global
    person identifier and an email address.

To query this table, I select the email addresses that belong to the
global person identifier, and then I select the email messages that came
from those email addresses.

This is accomplished through a filter on either a join or a subquery.
The difficulty is knowing which columns you're allowed to do this on.

How to implement this? I'm thinking that I find some way to encode this
in the SQLAlchemy objects and then I write something in the base classes
that allows me to encode the model in R or Postgres. I'll produce R or
SQL that will allow me to do these things.

* List the cubes.
* List the dimensions I can use on a cube.
* Filter cubes based on exact matches.
* Assemble the full joined table.

I think I can do all this by creating views that do all the joins and
add a column per dimension and by perhaps marking that filters are best
applied to columns that are at the tips of the snowflake (so on global
person identifiers rather than on email addresses, for example).

I'll wind up with four kinds of tables.

* Dimensions
* Facts
* Cubes (views)
* Helpers (for many-to-many relationships, I think)
